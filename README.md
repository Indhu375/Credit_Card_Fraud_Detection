ğŸ’³ Credit Card Fraud Detection

A comprehensive machine learning project for detecting fraudulent credit card transactions using various classification algorithms and advanced techniques to handle highly imbalanced data.

ğŸ“‹ Table of Contents

Project Overview

Dataset

Features

Installation

Usage

Methodology

Results

Project Structure

Contributing

ğŸ¯ Project Overview

This project implements a machine learning solution for credit card fraud detection, addressing the critical challenge of identifying fraudulent transactions in highly imbalanced datasets. The system employs various data preprocessing techniques, multiple machine learning algorithms, and comprehensive evaluation metrics to achieve optimal fraud detection performance.

Key Highlights:

ğŸ¯ High Precision & Recall for fraud detection

âš–ï¸ Handles class imbalance using SMOTE and other techniques

ğŸ“Š Comprehensive model evaluation with multiple metrics

ğŸ” Explainable AI with feature importance analysis

ğŸš€ Production-ready pipeline implementation

ğŸ“Š Dataset

Source : 

The project uses the popular Credit Card Fraud Detection dataset from Kaggle, containing transactions made by European cardholders in September 2013.

Dataset Characteristics

<img width="857" height="292" alt="image" src="https://github.com/user-attachments/assets/5607fd9e-0680-4318-908c-dcd70bba9d03" />


Features Description

V1-V28: Principal components obtained from PCA transformation (anonymized for privacy)

Time: Seconds elapsed between each transaction and the first transaction

Amount: Transaction amount

Class: Target variable (1 = Fraud, 0 = Legitimate)

ğŸ›  Features

ğŸ”§ Technical Features

Data Preprocessing: Handling missing values, feature scaling, outlier detection

Exploratory Data Analysis: Statistical analysis, correlation studies, distribution visualization

Class Imbalance Handling: SMOTE, Random UnderSampling, class weights

Multiple Algorithms: Random Forest, Logistic Regression, XGBoost, and more

Model Evaluation: Precision, Recall, F1-score, AUC-ROC, Confusion Matrix

ğŸ“ˆ Model Performance

High Recall: Minimizing false negatives (missed fraud cases)

Balanced Precision: Reducing false positives (legitimate transactions flagged as fraud)

ROC-AUC: Comprehensive model performance assessment

ğŸš€ Installation

Prerequisites
Python 3.8 or higher

pip (Python package manager)

Step-by-Step Installation

1. Clone the Repository
   
   git clone https://github.com/Indhu375/CreditCardFraudDetection.git
   
   cd CreditCardFraudDetection\
   
3. Create Virtual Environment
   
   python -m venv fraudenv
   
   source fraudenv/bin/activate  # On Windows: fraudenv\Scripts\activate
   
5. Install Dependencies
   
   pip install -r requirements.txt

Required Packages

The requirements.txt includes:

pandas>=1.3.0

numpy>=1.21.0

scikit-learn>=1.0.0

matplotlib>=3.5.0

seaborn>=0.11.0

imbalanced-learn>=0.9.0

xgboost>=1.5.0

jupyter>=1.0.0

ğŸ’» Usage

Running in Jupyter Notebook

  jupyter notebook

Running in Google Colab

Upload the notebook to Google Colab and ensure the dataset is available in your environment.

# Import and run the main pipeline

from src.pipeline import FraudDetectionPipeline

# Initialize pipeline

pipeline = FraudDetectionPipeline('data/creditcard.csv')

# Run complete analysis

results = pipeline.run_complete_analysis()

# Display results

pipeline.display_results()

ğŸ§ª Methodology

1. Data Preprocessing
   
  Feature Scaling: Standardization of Time and Amount features
  
  Handling Imbalance: SMOTE, RandomUnderSampler, and class weight adjustment
  
  Train-Test Split: Stratified splitting to maintain class distribution

2. Exploratory Data Analysis
   
  Statistical summary of features
  
  Correlation matrix analysis
  
  Distribution plots for legitimate vs fraudulent transactions

  Time and Amount feature analysis

3. Model Training
   
Algorithms Implemented:

  Logistic Regression
  
  Random Forest Classifier
  
  XGBoost Classifier
  
  Decision Tree Classifier
  
  Support Vector Machine

4. Model Evaluation
   
Metrics Used:

  Precision, Recall, F1-Score
  
  ROC-AUC Score
  
  Confusion Matrix
  
  Precision-Recall Curve

ğŸ“ˆ Results

Performance Comparison

<img width="1728" height="228" alt="image" src="https://github.com/user-attachments/assets/69d88d66-7791-403a-a448-adbfeee3649c" />

Key Findings

  Random Forest achieved the best balance between precision and recall
  
  SMOTE significantly improved model performance on minority class
  
  Feature Importance analysis revealed V14, V17, and V12 as most significant predictors

ğŸ“ Project Structure

<img width="647" height="598" alt="image" src="https://github.com/user-attachments/assets/ed26bf78-fb63-4c43-90d3-1105f8104cc4" />

ğŸ¤ Contributing

We welcome contributions! Please feel free to submit pull requests or open issues for improvements.

Contribution Guidelines

Fork the repository

Create a feature branch (git checkout -b feature/AmazingFeature)

Commit your changes (git commit -m 'Add some AmazingFeature')

Push to the branch (git push origin feature/AmazingFeature)

Open a Pull Request

